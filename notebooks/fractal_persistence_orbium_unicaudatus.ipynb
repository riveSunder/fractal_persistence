{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "run_local = True\n",
    "\n",
    "if run_local: \n",
    "    root_dir = \"..\"\n",
    "else:\n",
    "    os.system(\"git clone -b temp https://github.com/riveSunder/fractal_persistence/\")\n",
    "    os.system(\"mv fractal_persistence/* ./\")\n",
    "    os.system(\"! pip install -e .\")\n",
    "    os.system(\"! mkdir assets\")\n",
    "\n",
    "    root_dir = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from jax import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.animation \n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams[\"animation.embed_limit\"] = 1024\n",
    "\n",
    "import skimage\n",
    "import skimage.io as sio\n",
    "import skimage.transform\n",
    "import fracatal\n",
    "\n",
    "from fracatal.functional_jax.convolve import ft_convolve\n",
    "from fracatal.functional_jax.pad import pad_2d\n",
    "from fracatal.functional_jax.metrics import compute_entropy, compute_frequency_ratio, compute_frequency_entropy\n",
    "\n",
    "\n",
    "# imports being deprecated\n",
    "from fracatal.functional_jax.compose import make_gaussian, \\\n",
    "        make_mixed_gaussian, \\\n",
    "        make_kernel_field, \\\n",
    "        make_update_function, \\\n",
    "        make_update_step, \\\n",
    "        make_make_kernel_function, \\\n",
    "        sigmoid_1, \\\n",
    "        get_smooth_steps_fn, \\\n",
    "        make_make_smoothlife_kernel_function, \\\n",
    "        make_smooth_interval, \\\n",
    "        make_smoothlife_update_function, \\\n",
    "        make_smoothlife_update_step\n",
    "\n",
    "\n",
    "from fracatal.scripts.v_stability_sweep import v_stability_sweep\n",
    "from fracatal.scripts.stability_sweep import stability_sweep     \n",
    "from fracatal.scripts.mpi_sweep import mpi_stability_sweep\n",
    "\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "animation functions\n",
    "\"\"\"\n",
    "\n",
    "def get_fig(grid):\n",
    "    \n",
    "    global subplot_0\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    \n",
    "    subplot_0 = ax.imshow(grid.squeeze(), cmap=\"magma\")\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "def update_frame(ii):\n",
    "    \n",
    "    global grid\n",
    "    \n",
    "    subplot_0.set_array(grid.squeeze())\n",
    "    \n",
    "    grid = update_step(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common setup for orbium\n",
    "\n",
    "# the neighborhood kernel\n",
    "amplitudes = [1.0]\n",
    "means = [0.5]\n",
    "standard_deviations = [0.15]\n",
    "kernel_radius = 13\n",
    "\n",
    "make_kernel = make_make_kernel_function(amplitudes, means, standard_deviations)\n",
    "kernel = make_kernel(kernel_radius)\n",
    "\n",
    "# the growth function\n",
    "mean_g = 0.15\n",
    "standard_deviation_g = 0.017\n",
    "\n",
    "clipping_fn = lambda x: np.clip(x,0,1.0)\n",
    "my_update = make_update_function(mean_g, standard_deviation_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_name = \"orbium_unicaudatus\"\n",
    "pattern_filepath = os.path.join(root_dir, \"patterns\", f\"{pattern_name}.npy\")\n",
    "\n",
    "pattern = np.load(pattern_filepath)\n",
    "plt.figure()\n",
    "plt.imshow(pattern.squeeze(), cmap=\"magma\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(os.path.exists(os.path.join(root_dir, \"results\"))):\n",
    "    os.mkdir(os.path.join(root_dir, \"results\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_steps = 64\n",
    "stride = min([16, parameter_steps])\n",
    "max_t = 10\n",
    "max_steps = 10000\n",
    "max_growth = 1.3\n",
    "min_growth = 0.9\n",
    "k0 = 13\n",
    "grid_dim = 256\n",
    "default_dtype = np.float32\n",
    "\n",
    "kernel_dim = 122\n",
    "make_kernel = make_make_kernel_function(amplitudes, means, \\\n",
    "        standard_deviations, dim=kernel_dim, default_dtype=default_dtype)\n",
    "\n",
    "results = []\n",
    "t0 = time.time()\n",
    "\n",
    "max_runtime = 60*360.0\n",
    "max_zooms = 12\n",
    "total_zooms = 0\n",
    "\n",
    "time_elapsed = time.time()-t0\n",
    "time_stamp = int(t0*1000)\n",
    "params = [4, 72, 0.01, 1.05]\n",
    "\n",
    "freq_zoom_strides = 5\n",
    "freq_zoom_fraction = 2\n",
    "idx = 0\n",
    "\n",
    "exp_name = f\"{pattern_name}_{time_stamp}\"\n",
    "save_dir = os.path.join(root_dir, \"results\", exp_name)\n",
    "\n",
    "if os.path.exists(save_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "metadata_path = os.path.join(save_dir, f\"metadata_{time_stamp}.txt\")\n",
    "metadata = \"index, pattern_name, min_dt, max_dt, min_kr, max_kr, parameter_steps, max_t, max_steps, max_runtime, \"\n",
    "metadata += \"time_stamp, sim_time_elapsed,  total_time_elapsed, \"\n",
    "metadata += \"img_savepath, accumulated_t_savepath, total_steps_savepath, explode_savepath, vanish_savepath, grid_T_savepath\\n\"\n",
    "\n",
    "with open(metadata_path,\"w\") as f:\n",
    "    f.write(metadata)\n",
    "\n",
    "while time_elapsed <= max_runtime and total_zooms <= max_zooms:\n",
    "    \n",
    "    min_kr = params[0]\n",
    "    max_kr = params[1]\n",
    "    min_dt = params[2]\n",
    "    max_dt = params[3]\n",
    "\n",
    "    t1 = time.time()\n",
    "    \n",
    "    \n",
    "    results.append(stability_sweep(pattern, make_kernel, my_update, \\\n",
    "            max_t=max_t, max_steps=max_steps, parameter_steps=parameter_steps, stride=stride,\\\n",
    "            min_dt=min_dt, max_dt=max_dt,\\\n",
    "            min_kr = min_kr, max_kr=max_kr, k0=k0, \\\n",
    "            default_dtype=default_dtype))\n",
    "   \n",
    "    t2 = time.time()\n",
    "\n",
    "    fig, ax = plt.subplots(1,1, figsize=(12,12))\n",
    "    ax.imshow(results[-1][0])\n",
    "    dts = np.arange(min_dt, max_dt, (max_dt-min_dt) / parameter_steps)\n",
    "    krs = np.arange(min_kr, max_kr, (max_kr-min_kr) / parameter_steps)\n",
    "    \n",
    "    number_ticklabels = 16\n",
    "    ticklabel_period = parameter_steps // number_ticklabels\n",
    "    yticklabels = [f\"{elem.item():.6e}\" if not(mm % ticklabel_period) else \"\" for mm, elem in enumerate(dts)]\n",
    "    xticklabels = [f\"{elem.item():.6e}\" if not(mm % ticklabel_period) else \"\" for mm, elem in enumerate(krs)]\n",
    "    \n",
    "    _ = ax.set_yticks(np.arange(0,dts.shape[0]))\n",
    "    _ = ax.set_yticklabels(yticklabels, fontsize=16,  rotation=0)\n",
    "    _ = ax.set_xticks(np.arange(0,krs.shape[0]))\n",
    "    _ = ax.set_xticklabels(xticklabels, fontsize=16, rotation=90)\n",
    "    _ = ax.set_ylabel(\"step size dt\", fontsize=22)\n",
    "    _ = ax.set_xlabel(\"kernel radius\", fontsize=22)\n",
    "    \n",
    "    msg2 = f\"total elapsed: {t2-t0:.3f} s, last sweep: {t2-t1:.3f}\\n\"\n",
    "    msg = f\"    dt from {min_dt:.2e} to {max_dt:.2e}\\n\"\n",
    "    msg += f\"    kr from {min_kr:2e} to {max_kr:.2e}\\n\"\n",
    "    \n",
    "    ax.set_title(\"disco persistence \\n\" +msg, fontsize=24)\n",
    "    plt.savefig(f\"../assets/disco{time_stamp}_{idx}.png\")\n",
    "    plt.show() \n",
    "       \n",
    "    print(msg2 + msg)\n",
    "    # save results\n",
    "    # results_img, accumulated_t, total_steps, explode, vanish, done, grid_0, grid\n",
    "    \n",
    "    img_savepath = os.path.join(save_dir, f\"{exp_name}_img_{idx}.png\")\n",
    "    img_npy_savepath = os.path.join(save_dir, f\"{exp_name}_img_{idx}.npy\")\n",
    "    \n",
    "    accumulated_t_savepath = os.path.join(save_dir, f\"{exp_name}_accumulated_t_{idx}.npy\")\n",
    "    total_steps_savepath = os.path.join(save_dir, f\"{exp_name}_total_steps_{idx}.npy\")\n",
    "    \n",
    "    explode_savepath = os.path.join(save_dir, f\"{exp_name}_explode_{idx}.npy\")\n",
    "    vanish_savepath = os.path.join(save_dir, f\"{exp_name}_vanish_{idx}.npy\")\n",
    "    done_savepath = os.path.join(save_dir, f\"{exp_name}_done_{idx}.npy\")\n",
    "    \n",
    "    grid_0_savepath = os.path.join(save_dir, f\"{exp_name}_grid_0_{idx}.npy\")\n",
    "    grid_T_savepath = os.path.join(save_dir, f\"{exp_name}_grid_T_{idx}.npy\")\n",
    "                                    \n",
    "    sio.imsave(img_savepath, results[-1][0])\n",
    "    np.save(img_npy_savepath, results[-1][0])\n",
    "    np.save(accumulated_t_savepath, results[-1][1])\n",
    "    np.save(total_steps_savepath, results[-1][2])\n",
    "    np.save(explode_savepath, results[-1][3])\n",
    "    np.save(vanish_savepath, results[-1][4])\n",
    "    np.save(done_savepath, results[-1][5])\n",
    "    np.save(grid_0_savepath, results[-1][6])\n",
    "    np.save(grid_T_savepath, results[-1][7])\n",
    "    \n",
    "    # log experiment metadata\n",
    "    #metadata = \"index, min_dt, max_dt, min_kr, max_kr, parameter_steps, time_stamp, \"\n",
    "    #metadata += \"img_savepath, accumulated_t_savepath, total_steps_savepath, explode_savepath, vanish_savepath, grid_T_savepath\\n\"\n",
    "\n",
    "    metadata = f\"{idx}, {pattern_name}, {min_dt}, {max_dt}, {min_kr}, {max_kr}, {parameter_steps}, {max_t}, {max_steps}, {max_runtime}, \"\n",
    "    metadata += f\"{time_stamp}, {t2-t1:2f}, {t2-t0:2f}, \"\n",
    "    metadata += f\"{img_savepath}, {accumulated_t_savepath}, {total_steps_savepath}, {explode_savepath}, {vanish_savepath}, {grid_T_savepath}\\n\"\n",
    "    with open(metadata_path,\"a\") as f:\n",
    "        f.write(metadata)\n",
    "        \n",
    "    # determine next parameter range\n",
    "    freq_zoom_dim = (results[-1][0].shape[-2]) // freq_zoom_fraction\n",
    "    freq_zoom_stride = 4 + int(parameter_steps/16)\n",
    "    freq_zoom_strides = (results[-1][0].shape[-2]-freq_zoom_dim) // freq_zoom_stride +1\n",
    "    \n",
    "    fzd = freq_zoom_dim\n",
    "    fzs = freq_zoom_stride\n",
    "    \n",
    "    params_list = []\n",
    "    entropy = []\n",
    "    frequency_entropy = []\n",
    "    frequency_ratio = []\n",
    "    # Weighted RGB conversion to grayscale\n",
    "    gray_image = (1.0 - results[-1][5])\n",
    "            #0.29 * results[-1][0][:,:,0] \\\n",
    "            #+ 0.6*results[-1][0][:,:,1] \\\n",
    "            #+ 0.11 * results[-1][0][:,:,2]  \n",
    "    \n",
    "    for ll in range(freq_zoom_strides**2):\n",
    "        fzd = freq_zoom_dim\n",
    "        fzs = freq_zoom_stride\n",
    "        \n",
    "        cx = int(np.floor(ll / freq_zoom_strides))\n",
    "        cy = ll % freq_zoom_strides\n",
    "        \n",
    "        params_list.append([krs[cy*fzs].item(), \\\n",
    "                krs[cy*fzs+fzd].item(),\\\n",
    "                dts[cx*fzs].item(), \\\n",
    "                dts[cx*fzs+fzd].item()])\n",
    "\n",
    "\n",
    "        subimage = gray_image[cx*fzs:cx*fzs+fzd,cy*fzs:cy*fzs+fzd]\n",
    "        \n",
    "        frequency_ratio.append(compute_frequency_ratio(subimage))\n",
    "        entropy.append(compute_entropy(subimage))\n",
    "        frequency_entropy.append(compute_frequency_entropy(subimage))\n",
    "        \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(221)\n",
    "    plt.imshow(gray_image.squeeze())\n",
    "    plt.title(\"results image\")\n",
    "    plt.subplot(222)\n",
    "    plt.imshow(np.array(frequency_ratio).reshape(freq_zoom_strides, freq_zoom_strides))\n",
    "    plt.title(\"freq. ratio\")\n",
    "    plt.subplot(223)\n",
    "    plt.imshow(np.array(entropy).reshape(freq_zoom_strides, freq_zoom_strides))\n",
    "    plt.title(\"entropy\")\n",
    "    plt.subplot(224)\n",
    "    plt.imshow(np.array(frequency_entropy).reshape(freq_zoom_strides, freq_zoom_strides))\n",
    "    plt.title(\"frequency entropy\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{root_dir}/assets/frequency_entropy_{time_stamp}_{idx}.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    params_list_nonblank =  np.array(params_list)[np.array(entropy) > 0]\n",
    "    frequency_entropy_nonblank = np.array(frequency_entropy)[np.array(entropy) > 0]\n",
    "    params = params_list_nonblank[np.argmax(np.array(frequency_entropy_nonblank))]\n",
    "\n",
    "    t3 = time.time()\n",
    "    idx += 1    \n",
    "    time_elapsed = t3-t0\n",
    "    total_zooms += 1\n",
    "    \n",
    "    if np.sum(gray_image) == 0:\n",
    "        print(\"zoom no longer interesting, quitting\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "stability_sweep 4x at 32x32\n",
    "total elapsed: 1355.300 s, last sweep: 203.198\n",
    "    dt from 1.72e-01 to 3.02e-01\n",
    "    kr from 2.650000e+01 to 3.40e+01\n",
    "\n",
    "v_stability_sweep only 2x at 32x32\n",
    "total elapsed: 1041.628 s, last sweep: 509.198\n",
    "    dt from 1.00e-02 to 5.30e-01\n",
    "    kr from 1.900000e+01 to 4.90e+01\n",
    "\"\"\"\n",
    "\n",
    "# 3x local runs in float16 takes ~255 s (didn't work, update_step used float32)\n",
    "# 3x local runs in float16 takes ~224 s (after fix)\n",
    "# 3x local runs in float32 takes ~213 s (after fix)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
